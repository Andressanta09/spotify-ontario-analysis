{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016706dc",
   "metadata": {},
   "source": [
    "# Spotify Ontario Music Data Collection\n",
    "\n",
    "This notebook handles the collection of music data from Spotify, focusing on playlists related to Ontario. The process is structured in three main steps:\n",
    "\n",
    "1. Initial Setup and Authentication\n",
    "2. Playlist Collection\n",
    "3. Track and Audio Feature Collection\n",
    "\n",
    "## Configuration and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d44d7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 12:37:44,618 - INFO - ✅ Spotify connection successful\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Load environment variables and set up directories\n",
    "load_dotenv()\n",
    "RAW_DATA_DIR = \"../data/raw\"\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize Spotify client with proper authentication\n",
    "def init_spotify_client():\n",
    "    \"\"\"Initialize authenticated Spotify client with necessary permissions.\"\"\"\n",
    "    try:\n",
    "        auth_manager = SpotifyOAuth(\n",
    "            client_id=os.getenv(\"SPOTIFY_CLIENT_ID\"),\n",
    "            client_secret=os.getenv(\"SPOTIFY_CLIENT_SECRET\"),\n",
    "            redirect_uri=os.getenv(\"SPOTIFY_REDIRECT_URI\", \"http://127.0.0.1:8080/callback\"),\n",
    "            scope=\"playlist-read-private playlist-read-collaborative\",\n",
    "            cache_path=\".spotify_cache\"\n",
    "        )\n",
    "        client = spotipy.Spotify(auth_manager=auth_manager)\n",
    "        \n",
    "        # Test connection\n",
    "        if client.search(q=\"test\", limit=1):\n",
    "            logging.info(\"✅ Spotify connection successful\")\n",
    "            return client\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Failed to initialize Spotify client: {e}\")\n",
    "        raise\n",
    "\n",
    "# Initialize global client\n",
    "sp = init_spotify_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011df0b8",
   "metadata": {},
   "source": [
    "## Playlist Collection Functions\n",
    "\n",
    "Functions to search and collect playlist data from Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b7b6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 12:37:45,430 - ERROR - ❌ Error searching for 'Ontario music': 'NoneType' object is not subscriptable\n",
      "2025-09-18 12:37:46,051 - ERROR - ❌ Error searching for 'Ontario artists': 'NoneType' object is not subscriptable\n",
      "2025-09-18 12:37:46,765 - ERROR - ❌ Error searching for 'Ontario bands': 'NoneType' object is not subscriptable\n",
      "2025-09-18 12:37:47,577 - ERROR - ❌ Error searching for 'Toronto music': 'NoneType' object is not subscriptable\n",
      "2025-09-18 12:37:48,399 - ERROR - ❌ Error searching for 'Canadian indie': 'NoneType' object is not subscriptable\n",
      "2025-09-18 12:37:48,402 - INFO - Total playlists collected: 43\n"
     ]
    }
   ],
   "source": [
    "def search_playlists(keywords, limit=50):\n",
    "    \"\"\"\n",
    "    Search Spotify playlists based on keywords.\n",
    "    \n",
    "    Args:\n",
    "        keywords (list): List of search terms\n",
    "        limit (int): Maximum playlists per keyword\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed playlist information\n",
    "    \"\"\"\n",
    "    playlists = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            results = sp.search(q=keyword, type='playlist', limit=limit)\n",
    "            for playlist in results['playlists']['items']:\n",
    "                playlists.append({\n",
    "                    'id': playlist['id'],\n",
    "                    'name': playlist['name'],\n",
    "                    'description': playlist['description'],\n",
    "                    'owner': playlist['owner']['display_name'],\n",
    "                    'tracks_total': playlist['tracks']['total'],\n",
    "                    'followers': playlist['followers']['total'] if 'followers' in playlist else 0,\n",
    "                    'keyword': keyword\n",
    "                })\n",
    "            logging.info(f\"✅ Found {len(results['playlists']['items'])} playlists for '{keyword}'\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"❌ Error searching for '{keyword}': {e}\")\n",
    "    \n",
    "    df = pd.DataFrame(playlists)\n",
    "    logging.info(f\"Total playlists collected: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# Define search keywords\n",
    "ontario_keywords = [\n",
    "    'Ontario music',\n",
    "    'Ontario artists',\n",
    "    'Ontario bands',\n",
    "    'Toronto music',\n",
    "    'Canadian indie'\n",
    "]\n",
    "\n",
    "# Collect playlists\n",
    "playlists_df = search_playlists(ontario_keywords, limit=MAX_PLAYLISTS_PER_KEYWORD)\n",
    "\n",
    "# Save raw data with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "playlists_df.to_csv(f\"{RAW_DATA_DIR}/playlists_{timestamp}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455bfbcf",
   "metadata": {},
   "source": [
    "## Track Collection and Audio Features\n",
    "\n",
    "Functions to collect track information and audio features from the playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21db1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_tracks(playlist_id):\n",
    "    \"\"\"Get all tracks from a playlist with their basic information.\"\"\"\n",
    "    tracks = []\n",
    "    try:\n",
    "        results = sp.playlist_tracks(playlist_id)\n",
    "        while results:\n",
    "            for item in results['items']:\n",
    "                if not item['track']:\n",
    "                    continue\n",
    "                    \n",
    "                track = item['track']\n",
    "                tracks.append({\n",
    "                    'id': track['id'],\n",
    "                    'name': track['name'],\n",
    "                    'artist': track['artists'][0]['name'],\n",
    "                    'artist_id': track['artists'][0]['id'],\n",
    "                    'album': track['album']['name'],\n",
    "                    'album_id': track['album']['id'],\n",
    "                    'popularity': track['popularity'],\n",
    "                    'duration_ms': track['duration_ms'],\n",
    "                    'explicit': track['explicit'],\n",
    "                    'release_date': track['album']['release_date'],\n",
    "                    'playlist_id': playlist_id\n",
    "                })\n",
    "            \n",
    "            results = sp.next(results) if results['next'] else None\n",
    "            time.sleep(RATE_LIMIT_DELAY)  # Rate limiting\n",
    "        \n",
    "        logging.info(f\"✅ Retrieved {len(tracks)} tracks from playlist {playlist_id}\")\n",
    "        return tracks\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Error fetching tracks from playlist {playlist_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_audio_features_batch(track_ids):\n",
    "    \"\"\"Get audio features for a batch of tracks.\"\"\"\n",
    "    try:\n",
    "        features = sp.audio_features(track_ids)\n",
    "        return [f for f in features if f]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Error fetching audio features: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66e425a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_rate_limit(e=None, base_wait=2):\n",
    "    \"\"\"Respect Spotify rate limit using Retry-After if available\"\"\"\n",
    "    wait_time = base_wait\n",
    "    if e and hasattr(e, \"http_headers\") and \"Retry-After\" in e.http_headers:\n",
    "        wait_time = int(e.http_headers[\"Retry-After\"])\n",
    "    logging.warning(f\"⏳ Rate limited. Waiting {wait_time}s...\")\n",
    "    time.sleep(wait_time)\n",
    "    return True  # Indicate successful wait\n",
    "\n",
    "def log_failed_ids(track_ids, reason):\n",
    "    \"\"\"Log failed track IDs with timestamp and reason\"\"\"\n",
    "    log_dir = os.path.join(\"..\", \"logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = os.path.join(log_dir, \"failed_ids.log\")\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    try:\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(f\"\\n[{timestamp}] {reason}\\n\")\n",
    "            for tid in track_ids:\n",
    "                f.write(f\"{tid}\\n\")\n",
    "        logging.warning(f\"⚠️ Logged {len(track_ids)} failed IDs: {reason}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Failed to log IDs: {e}\")\n",
    "        return False\n",
    "\n",
    "def retry_auth():\n",
    "    \"\"\"Refresh Spotify authentication token\"\"\"\n",
    "    try:\n",
    "        logging.info(\"🔄 Refreshing Spotify token...\")\n",
    "        global sp\n",
    "        sp = init_spotify_client()  # Use our existing OAuth setup\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Failed to refresh token: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_audio_features(track_ids, chunk_size=50, max_retries=3):\n",
    "    \"\"\"Process tracks in batches with improved error handling\"\"\"\n",
    "    if not track_ids:\n",
    "        return []\n",
    "\n",
    "    track_ids = list(set(track_ids))  # Remove duplicates\n",
    "    chunks = [track_ids[i:i + chunk_size] for i in range(0, len(track_ids), chunk_size)]\n",
    "    audio_features, failed_ids = [], set()\n",
    "\n",
    "    logging.info(f\"🎵 Processing {len(track_ids)} tracks in {len(chunks)} chunks\")\n",
    "\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                features = sp.audio_features(chunk)\n",
    "                valid = [f for f in features if f]\n",
    "                audio_features.extend(valid)\n",
    "                \n",
    "                # Track failed IDs\n",
    "                new_failed = set(chunk) - {f[\"id\"] for f in valid}\n",
    "                if new_failed:\n",
    "                    failed_ids.update(new_failed)\n",
    "                \n",
    "                logging.info(f\"✅ Chunk {i}/{len(chunks)}: {len(valid)}/{len(chunk)} processed\")\n",
    "                break  # Success - exit retry loop\n",
    "                \n",
    "            except spotipy.exceptions.SpotifyException as e:\n",
    "                if e.http_status == 403 and retry_auth():\n",
    "                    retries += 1\n",
    "                    continue\n",
    "                elif handle_rate_limit(e):\n",
    "                    continue\n",
    "                else:\n",
    "                    failed_ids.update(chunk)\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logging.error(f\"❌ Chunk {i} error: {e}\")\n",
    "                retries += 1\n",
    "                if retries >= max_retries:\n",
    "                    failed_ids.update(chunk)\n",
    "\n",
    "    # Log failed tracks if any\n",
    "    if failed_ids:\n",
    "        log_failed_ids(failed_ids, \"Failed after all retries\")\n",
    "\n",
    "    success_rate = (len(audio_features) / len(track_ids)) * 100\n",
    "    logging.info(f\"📊 Final results: {len(audio_features)}/{len(track_ids)} tracks ({success_rate:.1f}%)\")\n",
    "    \n",
    "    return audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24803ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 12:39:51,604 - INFO - ✅ Retrieved 31 tracks from playlist 0H5sLEc8WnoXmrXgZ1QA5R\n",
      "2025-09-18 12:39:52,212 - INFO - ✅ Retrieved 76 tracks from playlist 2wfNEHp2xeD3LBv4m01rPT\n",
      "2025-09-18 12:39:52,212 - INFO - ✅ Retrieved 76 tracks from playlist 2wfNEHp2xeD3LBv4m01rPT\n",
      "2025-09-18 12:39:52,475 - INFO - ✅ Retrieved 16 tracks from playlist 66XDl402XcPVosSaF8LONU\n",
      "2025-09-18 12:39:52,475 - INFO - ✅ Retrieved 16 tracks from playlist 66XDl402XcPVosSaF8LONU\n",
      "2025-09-18 12:39:52,775 - INFO - ✅ Retrieved 16 tracks from playlist 6EsrPeJZG00trXEG6MsGMi\n",
      "2025-09-18 12:39:52,775 - INFO - ✅ Retrieved 16 tracks from playlist 6EsrPeJZG00trXEG6MsGMi\n",
      "2025-09-18 12:39:58,484 - INFO - ✅ Retrieved 860 tracks from playlist 32uH7sB8TAl03OtVOUuJzy\n",
      "2025-09-18 12:39:58,484 - INFO - ✅ Retrieved 860 tracks from playlist 32uH7sB8TAl03OtVOUuJzy\n",
      "2025-09-18 12:39:59,451 - INFO - ✅ Retrieved 103 tracks from playlist 1lQElxu7q2z09LPdFuoL4l\n",
      "2025-09-18 12:39:59,451 - INFO - ✅ Retrieved 103 tracks from playlist 1lQElxu7q2z09LPdFuoL4l\n",
      "2025-09-18 12:40:01,536 - INFO - ✅ Retrieved 278 tracks from playlist 0bxoXZPLBDZbCC8GGcDr0H\n",
      "2025-09-18 12:40:01,536 - INFO - ✅ Retrieved 278 tracks from playlist 0bxoXZPLBDZbCC8GGcDr0H\n",
      "2025-09-18 12:40:02,163 - INFO - ✅ Retrieved 56 tracks from playlist 7pBLyLVQ9vX8o1iiH8Qrmc\n",
      "2025-09-18 12:40:02,163 - INFO - ✅ Retrieved 56 tracks from playlist 7pBLyLVQ9vX8o1iiH8Qrmc\n",
      "2025-09-18 12:40:02,569 - INFO - ✅ Retrieved 33 tracks from playlist 2kX6Hug03CcVUMrtYAUvoL\n",
      "2025-09-18 12:40:02,569 - INFO - ✅ Retrieved 33 tracks from playlist 2kX6Hug03CcVUMrtYAUvoL\n",
      "2025-09-18 12:40:03,050 - INFO - ✅ Retrieved 32 tracks from playlist 3cgX4KU5WKMlEB7gyIBZJ9\n",
      "2025-09-18 12:40:03,050 - INFO - ✅ Retrieved 32 tracks from playlist 3cgX4KU5WKMlEB7gyIBZJ9\n",
      "2025-09-18 12:40:03,521 - INFO - ✅ Retrieved 28 tracks from playlist 7hJWJFKIeVHugbH4lF5zlm\n",
      "2025-09-18 12:40:03,521 - INFO - ✅ Retrieved 28 tracks from playlist 7hJWJFKIeVHugbH4lF5zlm\n",
      "2025-09-18 12:40:04,698 - INFO - ✅ Retrieved 135 tracks from playlist 5ULCXRFvjfLdIFTHe65avh\n",
      "2025-09-18 12:40:04,698 - INFO - ✅ Retrieved 135 tracks from playlist 5ULCXRFvjfLdIFTHe65avh\n",
      "2025-09-18 12:40:05,106 - INFO - ✅ Retrieved 26 tracks from playlist 12sc6OYCi10ARKFJroeSJr\n",
      "2025-09-18 12:40:05,106 - INFO - ✅ Retrieved 26 tracks from playlist 12sc6OYCi10ARKFJroeSJr\n",
      "2025-09-18 12:40:05,599 - INFO - ✅ Retrieved 42 tracks from playlist 0i6cMd1j8uY0wEnluZuKqk\n",
      "2025-09-18 12:40:05,599 - INFO - ✅ Retrieved 42 tracks from playlist 0i6cMd1j8uY0wEnluZuKqk\n",
      "2025-09-18 12:40:06,038 - INFO - ✅ Retrieved 29 tracks from playlist 2HO8OGs6zBNCAbXwV7CdOZ\n",
      "2025-09-18 12:40:06,038 - INFO - ✅ Retrieved 29 tracks from playlist 2HO8OGs6zBNCAbXwV7CdOZ\n",
      "2025-09-18 12:40:06,429 - INFO - ✅ Retrieved 20 tracks from playlist 3Zfc35wXiH2zChgZeYtl6y\n",
      "2025-09-18 12:40:06,429 - INFO - ✅ Retrieved 20 tracks from playlist 3Zfc35wXiH2zChgZeYtl6y\n",
      "2025-09-18 12:40:06,837 - INFO - ✅ Retrieved 30 tracks from playlist 5ysIJjV5BgJPWjuY4efOJN\n",
      "2025-09-18 12:40:06,837 - INFO - ✅ Retrieved 30 tracks from playlist 5ysIJjV5BgJPWjuY4efOJN\n",
      "2025-09-18 12:40:07,228 - INFO - ✅ Retrieved 10 tracks from playlist 6wT6kcSOKPd88IgmG6Oj8F\n",
      "2025-09-18 12:40:07,228 - INFO - ✅ Retrieved 10 tracks from playlist 6wT6kcSOKPd88IgmG6Oj8F\n",
      "2025-09-18 12:40:08,069 - INFO - ✅ Retrieved 83 tracks from playlist 7HXb6TBIGgwsqz7o2PYlLZ\n",
      "2025-09-18 12:40:08,069 - INFO - ✅ Retrieved 83 tracks from playlist 7HXb6TBIGgwsqz7o2PYlLZ\n",
      "2025-09-18 12:40:09,693 - INFO - ✅ Retrieved 215 tracks from playlist 1NcQpeRSlkjvwuPEzd2yvZ\n",
      "2025-09-18 12:40:09,693 - INFO - ✅ Retrieved 215 tracks from playlist 1NcQpeRSlkjvwuPEzd2yvZ\n",
      "2025-09-18 12:40:10,909 - INFO - ✅ Retrieved 170 tracks from playlist 1nJ2PxXdRLpiXk8OaxWbiH\n",
      "2025-09-18 12:40:10,909 - INFO - ✅ Retrieved 170 tracks from playlist 1nJ2PxXdRLpiXk8OaxWbiH\n",
      "2025-09-18 12:40:11,410 - INFO - ✅ Retrieved 10 tracks from playlist 2jkaUIDU5ceW8F9Ligwz5x\n",
      "2025-09-18 12:40:11,410 - INFO - ✅ Retrieved 10 tracks from playlist 2jkaUIDU5ceW8F9Ligwz5x\n",
      "2025-09-18 12:40:12,471 - INFO - ✅ Retrieved 111 tracks from playlist 2Tap0uZxvtuw9m9uKZbsD7\n",
      "2025-09-18 12:40:12,471 - INFO - ✅ Retrieved 111 tracks from playlist 2Tap0uZxvtuw9m9uKZbsD7\n",
      "2025-09-18 12:40:18,433 - INFO - ✅ Retrieved 860 tracks from playlist 32uH7sB8TAl03OtVOUuJzy\n",
      "2025-09-18 12:40:18,433 - INFO - ✅ Retrieved 860 tracks from playlist 32uH7sB8TAl03OtVOUuJzy\n",
      "2025-09-18 12:40:18,761 - INFO - ✅ Retrieved 16 tracks from playlist 6EsrPeJZG00trXEG6MsGMi\n",
      "2025-09-18 12:40:18,761 - INFO - ✅ Retrieved 16 tracks from playlist 6EsrPeJZG00trXEG6MsGMi\n",
      "2025-09-18 12:40:19,058 - INFO - ✅ Retrieved 17 tracks from playlist 6dYe8pEKPSYDIMb3S13bfr\n",
      "2025-09-18 12:40:19,058 - INFO - ✅ Retrieved 17 tracks from playlist 6dYe8pEKPSYDIMb3S13bfr\n",
      "2025-09-18 12:40:25,701 - INFO - ✅ Retrieved 888 tracks from playlist 5QLSfILROj8mnMwLFThPEL\n",
      "2025-09-18 12:40:25,701 - INFO - ✅ Retrieved 888 tracks from playlist 5QLSfILROj8mnMwLFThPEL\n",
      "2025-09-18 12:40:26,091 - INFO - ✅ Retrieved 17 tracks from playlist 4EDQJ9Wxf3QPSzyjVJscUC\n",
      "2025-09-18 12:40:26,091 - INFO - ✅ Retrieved 17 tracks from playlist 4EDQJ9Wxf3QPSzyjVJscUC\n",
      "2025-09-18 12:40:27,781 - INFO - ✅ Retrieved 253 tracks from playlist 4NpUvRzGah3Di8SRY6cZZA\n",
      "2025-09-18 12:40:27,781 - INFO - ✅ Retrieved 253 tracks from playlist 4NpUvRzGah3Di8SRY6cZZA\n",
      "2025-09-18 12:40:28,141 - INFO - ✅ Retrieved 13 tracks from playlist 7ELp988h8Cnyx8OSX0sTW8\n",
      "2025-09-18 12:40:28,141 - INFO - ✅ Retrieved 13 tracks from playlist 7ELp988h8Cnyx8OSX0sTW8\n",
      "2025-09-18 12:40:29,214 - INFO - ✅ Retrieved 116 tracks from playlist 3UPfuFzaCB3HCSwAOOGVmY\n",
      "2025-09-18 12:40:29,214 - INFO - ✅ Retrieved 116 tracks from playlist 3UPfuFzaCB3HCSwAOOGVmY\n",
      "2025-09-18 12:40:29,585 - INFO - ✅ Retrieved 25 tracks from playlist 32I6sdTRU7TkxZ0PGe4pZ3\n",
      "2025-09-18 12:40:29,585 - INFO - ✅ Retrieved 25 tracks from playlist 32I6sdTRU7TkxZ0PGe4pZ3\n",
      "2025-09-18 12:40:32,042 - INFO - ✅ Retrieved 312 tracks from playlist 4asoVXnZZSnf6CB586Wigz\n",
      "2025-09-18 12:40:32,042 - INFO - ✅ Retrieved 312 tracks from playlist 4asoVXnZZSnf6CB586Wigz\n",
      "2025-09-18 12:40:38,101 - INFO - ✅ Retrieved 770 tracks from playlist 0lvusniUzz3RBqBOlXSfAF\n",
      "2025-09-18 12:40:38,101 - INFO - ✅ Retrieved 770 tracks from playlist 0lvusniUzz3RBqBOlXSfAF\n",
      "2025-09-18 12:40:43,207 - INFO - ✅ Retrieved 625 tracks from playlist 0myFM9AwR26t2zaX3tjrPW\n",
      "2025-09-18 12:40:43,207 - INFO - ✅ Retrieved 625 tracks from playlist 0myFM9AwR26t2zaX3tjrPW\n",
      "2025-09-18 12:40:45,667 - INFO - ✅ Retrieved 290 tracks from playlist 7I304SOcxHiHWIxgqSGkrJ\n",
      "2025-09-18 12:40:45,667 - INFO - ✅ Retrieved 290 tracks from playlist 7I304SOcxHiHWIxgqSGkrJ\n",
      "2025-09-18 12:40:46,276 - INFO - ✅ Retrieved 49 tracks from playlist 4lF0rrkaqkl72KvdNrc5IO\n",
      "2025-09-18 12:40:46,276 - INFO - ✅ Retrieved 49 tracks from playlist 4lF0rrkaqkl72KvdNrc5IO\n",
      "2025-09-18 12:40:47,433 - INFO - ✅ Retrieved 149 tracks from playlist 4BNq7Fc1P54gn0o9WsnZRV\n",
      "2025-09-18 12:40:47,433 - INFO - ✅ Retrieved 149 tracks from playlist 4BNq7Fc1P54gn0o9WsnZRV\n",
      "2025-09-18 12:40:47,787 - INFO - ✅ Retrieved 17 tracks from playlist 7ABEs6l8smi9UA18u3My8L\n",
      "2025-09-18 12:40:47,787 - INFO - ✅ Retrieved 17 tracks from playlist 7ABEs6l8smi9UA18u3My8L\n",
      "2025-09-18 12:40:48,099 - INFO - ✅ Retrieved 16 tracks from playlist 6QjR1xhcT6p3FdbWUHYr0e\n",
      "2025-09-18 12:40:48,099 - INFO - ✅ Retrieved 16 tracks from playlist 6QjR1xhcT6p3FdbWUHYr0e\n",
      "2025-09-18 12:40:52,787 - INFO - ✅ Retrieved 625 tracks from playlist 0myFM9AwR26t2zaX3tjrPW\n",
      "2025-09-18 12:40:52,787 - INFO - ✅ Retrieved 625 tracks from playlist 0myFM9AwR26t2zaX3tjrPW\n",
      "2025-09-18 12:40:53,487 - INFO - ✅ Retrieved 94 tracks from playlist 1jprqPPwj00td7kSAee7wl\n",
      "2025-09-18 12:40:53,487 - INFO - ✅ Retrieved 94 tracks from playlist 1jprqPPwj00td7kSAee7wl\n",
      "2025-09-18 12:41:00,095 - INFO - ✅ Retrieved 720 tracks from playlist 6Mk9tStPFhrZmMOGckpFbA\n",
      "2025-09-18 12:41:00,098 - INFO - ✅ Total: 0 tracks (0 unique)\n",
      "2025-09-18 12:41:00,095 - INFO - ✅ Retrieved 720 tracks from playlist 6Mk9tStPFhrZmMOGckpFbA\n",
      "2025-09-18 12:41:00,098 - INFO - ✅ Total: 0 tracks (0 unique)\n"
     ]
    }
   ],
   "source": [
    "def collect_tracks(playlists_df, save_interval=50):\n",
    "    \"\"\"Extract tracks from playlists with periodic saving\"\"\"\n",
    "    if playlists_df.empty:\n",
    "        logging.warning(\"❌ No playlists available\")\n",
    "        return pd.DataFrame(), set()\n",
    "\n",
    "    all_tracks = []\n",
    "    track_ids = set()\n",
    "    save_dir = os.path.join(\"..\", \"data\", \"raw\", \"incremental\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    for i, pid in enumerate(playlists_df[\"id\"], 1):  # Cambiado de \"playlist_id\" a \"id\"\n",
    "        try:\n",
    "            tracks = get_playlist_tracks(pid)\n",
    "            track_infos = []\n",
    "            for item in tracks:\n",
    "                if item.get('track'):\n",
    "                    track = item['track']\n",
    "                    track_info = {\n",
    "                        'track_id': track['id'],\n",
    "                        'name': track['name'],\n",
    "                        'artist': track['artists'][0]['name'],\n",
    "                        'playlist_id': pid\n",
    "                    }\n",
    "                    track_infos.append(track_info)\n",
    "            \n",
    "            # Update collections\n",
    "            all_tracks.extend(track_infos)\n",
    "            new_ids = {ti[\"track_id\"] for ti in track_infos}\n",
    "            track_ids.update(new_ids)\n",
    "            \n",
    "            # Periodic save\n",
    "            if i % save_interval == 0:\n",
    "                temp_df = pd.DataFrame(all_tracks)\n",
    "                temp_df.to_csv(\n",
    "                    os.path.join(save_dir, f\"tracks_temp_{timestamp}_{i}.csv\"),\n",
    "                    index=False\n",
    "                )\n",
    "                logging.info(f\"💾 Saved checkpoint at playlist {i}/{len(playlists_df)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"❌ Error processing playlist {pid}: {e}\")\n",
    "            continue\n",
    "\n",
    "    final_df = pd.DataFrame(all_tracks)\n",
    "    logging.info(f\"✅ Total: {len(final_df)} tracks ({len(track_ids)} unique)\")\n",
    "    \n",
    "    return final_df, track_ids\n",
    "\n",
    "# === Usage ===\n",
    "tracks_df, track_ids = collect_tracks(playlists_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ff5d877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 12:41:00,127 - INFO - ℹ️ No track IDs to process\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def collect_audio_features(track_ids):\n",
    "    \"\"\"Get audio features for unique IDs and return a clean DataFrame\"\"\"\n",
    "    if not track_ids:\n",
    "        logging.info(\"ℹ️ No track IDs to process\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    logging.info(f\"🎶 Starting Audio Features Collection for {len(track_ids)} unique tracks\")\n",
    "\n",
    "    features = get_audio_features(track_ids)\n",
    "    if not features:\n",
    "        logging.warning(\"❌ No audio features collected\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(features)\n",
    "    success_rate = (len(df) / len(track_ids)) * 100\n",
    "    logging.info(f\"✅ Collected audio features for {len(df)}/{len(track_ids)} tracks ({success_rate:.1f}%)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# === Usage ===\n",
    "audio_features_df = collect_audio_features(track_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
